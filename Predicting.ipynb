{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtnZQkTu6tX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d39e3d2-d7bc-407e-d51f-8cf2fb4d1813"
      },
      "source": [
        "#Mount our google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/That Fake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "key_wRgjWFUX",
        "outputId": "b4b5be23-dcc1-4935-e524-f7aa92daf669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1kA6OIpsKA1jCcdU-bMhxs2O89QudlW2K/That Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IDrk4ewLItdV",
        "outputId": "6effe83d-af46-4689-8e61-2bcaba039372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1kA6OIpsKA1jCcdU-bMhxs2O89QudlW2K/That Fake'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing all the required libraries\n",
        "!pip3 install face_recognition\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "from tqdm.autonotebook import tqdm\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "teUornHp1Pdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
        "        super(Model, self).__init__()\n",
        "        model = models.resnext50_32x4d(pretrained = True) \n",
        "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
        "        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dp = nn.Dropout(0.4)\n",
        "        self.linear1 = nn.Linear(2048,num_classes)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    def forward(self, x):\n",
        "        batch_size,seq_length, c, h, w = x.shape\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        fmap = self.model(x)\n",
        "        x = self.avgpool(fmap)\n",
        "        x = x.view(batch_size,seq_length,2048)\n",
        "        x_lstm,_ = self.lstm(x,None)\n",
        "        return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))"
      ],
      "metadata": {
        "id": "D8WA4wwJzh2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_size = 112\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "sm = nn.Softmax()\n",
        "inv_normalize =  transforms.Normalize(mean=-1*np.divide(mean,std),std=np.divide([1,1,1],std))\n",
        "def im_convert(tensor):\n",
        "    image = tensor.to(\"cpu\").clone().detach()\n",
        "    image = image.squeeze()\n",
        "    image = inv_normalize(image)\n",
        "    image = image.numpy()\n",
        "    image = image.transpose(1,2,0)\n",
        "    image = image.clip(0, 1)\n",
        "    cv2.imwrite('/content/drive/MyDrive/That Fake/2.png',image*255)\n",
        "    return image\n",
        "\n",
        "def predict(model,img,path = './'):\n",
        "  fmap,logits = model(img.to('cuda'))\n",
        "  params = list(model.parameters())\n",
        "  weight_softmax = model.linear1.weight.detach().cpu().numpy()\n",
        "  logits = sm(logits)\n",
        "  _,prediction = torch.max(logits,1)\n",
        "  confidence = logits[:,int(prediction.item())].item()*100\n",
        "  print('confidence of prediction:',logits[:,int(prediction.item())].item()*100)\n",
        "  idx = np.argmax(logits.detach().cpu().numpy())\n",
        "  bz, nc, h, w = fmap.shape\n",
        "  out = np.dot(fmap[-1].detach().cpu().numpy().reshape((nc, h*w)).T,weight_softmax[idx,:].T)\n",
        "  predict = out.reshape(h,w)\n",
        "  predict = predict - np.min(predict)\n",
        "  predict_img = predict / np.max(predict)\n",
        "  predict_img = np.uint8(255*predict_img)\n",
        "  out = cv2.resize(predict_img, (im_size,im_size))\n",
        "  heatmap = cv2.applyColorMap(out, cv2.COLORMAP_JET)\n",
        "  img = im_convert(img[:,-1,:,:,:])\n",
        "  result = heatmap * 0.5 + img*0.8*255\n",
        "  cv2.imwrite('/content/drive/MyDrive/That Fake/1.png',result)\n",
        "  result1 = heatmap * 0.5/255 + img*0.8\n",
        "  r,g,b = cv2.split(result1)\n",
        "  result1 = cv2.merge((r,g,b))\n",
        "  plt.imshow(result1)\n",
        "  plt.show()\n",
        "  return [int(prediction.item()),confidence]"
      ],
      "metadata": {
        "id": "UAMRE_YBPDnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class validation_dataset(Dataset):\n",
        "    def __init__(self,video_names,sequence_length = 100,transform = None):\n",
        "        self.video_names = video_names\n",
        "        self.transform = transform\n",
        "        self.count = sequence_length\n",
        "    def __len__(self):\n",
        "        return len(self.video_names)\n",
        "    def __getitem__(self,idx):\n",
        "        video_path = self.video_names[idx]\n",
        "        frames = []\n",
        "        a = int(100/self.count)\n",
        "        first_frame = np.random.randint(0,a) \n",
        "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
        "          frames.append(self.transform(frame))\n",
        "          if(len(frames) == self.count):\n",
        "            break\n",
        "        frames = torch.stack(frames)\n",
        "        frames = frames[:self.count]\n",
        "        return frames.unsqueeze(0)\n",
        "    def frame_extract(self,path):\n",
        "      vidObj = cv2.VideoCapture(path) \n",
        "      success = 1\n",
        "      while success:\n",
        "          success, image = vidObj.read()\n",
        "          if success:\n",
        "              yield image"
      ],
      "metadata": {
        "id": "PIogVRumagWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Code for making prediction\n",
        "im_size = 112\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "test_labels=[]\n",
        "#test_id=[]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "\n",
        "\n",
        "\n",
        "path_to_videos=[]\n",
        "path_to_videos=glob.glob('/content/drive/MyDrive/That Fake/deepfake-detection/deep-fake-dataset/test/*.mp4')\n",
        "\n",
        "\n",
        "video_dataset = validation_dataset(path_to_videos,sequence_length = 15,transform = train_transforms)\n",
        "\n",
        "#path_to_model = '/content/drive/MyDrive/That Fake1/checkpoint.pt'\n",
        "\n",
        "model = pickle.load(open('/content/drive/MyDrive/That Fake/OG_Pretrained_Test_model_epoch_20+4.sav', 'rb'))\n",
        "\n",
        "model.eval()\n",
        "for i in range(0,len(path_to_videos)):\n",
        "  print(path_to_videos[i])\n",
        "  prediction = predict(model,video_dataset[i],'./')\n",
        " \n",
        "  if prediction[0] == 1:\n",
        "    print(\"REAL\")\n",
        "    test_labels.append(1)\n",
        "  else:\n",
        "    print(\"FAKE\")\n",
        "    test_labels.append(0)"
      ],
      "metadata": {
        "id": "PF_3XBHIPL6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}